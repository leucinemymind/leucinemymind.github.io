---
title: "Which AI writes better tutorials?"
date: 2025-07-09
tags: [LaTeX]
---

## The ubiquity of AI

There are people who use AI, people who don’t use AI, and people who use AI but insist they don’t, saying, “Oh, I *never* use AI. I only ever use it for \*insert task\* and \*insert task\* and \*insert task\*! I’m not contributing to any adverse side effects of AI usage whatsoever!”

But regardless of how you feel about AI, it’s here, it’s everywhere, and it’s changing how we work. I can’t exactly gauge the extent to which AI is affecting our environment, but I do know that working with computers has become an indispensable skill in the workplace no matter what field you’re in, STEM or not. I recently heard a structural biologist’s talk on the history of structural biology, and he advised us to take data science and coding courses to make our lives easier because computers are the future of structural biology.

My friends remember receiving a flurry of texts from me immediately after the [2024 Nobel Prize in chemistry](https://www.nobelprize.org/prizes/chemistry/2024/press-release/) was announced. Half to David Baker, the other half split between Demis Hassabis and John Jumper for their work on computational biology. I’ve done a few things with AlphaFold myself and was blown away by just how figureoutable it was, having initially expected to have to work with a much more cryptic interface.

No matter what your stance is on issues surrounding AI, it is *incredible.* Whether you interpret that with a negative or positive connotation, there’s no denying it. Since AI started popping up virtually *everywhere* - Snapchat, Instagram, GitHub, Google - we’ve been inseparable.

And you know I have nothing better to do with my day than to pitch these models against each other.

## The challenge

My most recent project has been a LaTeX beginner tutorial. I finished it just two months ago. That got me thinking - could AI replicate what took me from October to May to complete in a matter of minutes?

I focused on four main elements while writing my tutorial, calling them “Sara” affectionately because coining new terms is fun. They were, namely:

- **structure** including simplicity, readability, and style;
- **accuracy** - because besides subjective or nuanced topics, the information presented should be correct;
- **reproducibility** - I tried to run my example code exactly the way it was written (unless there was an explanation as to why it wasn’t);
- **authentic voice**, because no one wants to read boring documentation that looks like a robot made it.

Here, I’m giving three AIs one simple task: to create an engaging, beginner-friendly LaTeX tutorial…and we’ll see what happens.

## GitHub Copilot

The initial prompt:

> Can you write me a LaTeX tutorial using LaTeX? It should be easy, beginner-friendly, readable, and flow well.

With this prompt, Copilot generated a four-page tutorial that I can only describe as disappointing, not because I have randomly forged a rivalry with Copilot but because the formatting was all over the place and there was little to no coherence within the document. Plus, there were four errors already.

So, trying again:

> Can you make that longer, with sentences, clear explanations, and readable formatting?

At this point, the document was six pages instead of just four. Here there was obvious improvement in terms of formatting and aesthetics, but it wasn’t necessarily something you would want to read when you’re just getting started. So my third and final prompt was:

> Could you make that more engaging? Add whatever you think you need to really make the reader excited about learning LaTeX.

The response was…[magical?](https://www.overleaf.com/read/kfwbxwhjtwhv#46477d)

Thoughts on Copilot’s tutorial-writing skills:

- **structure** - 8.6/10. It's good, but the spilled text...
- **accuracy & reproducibility** - 7/10. You can’t expect Copilot to produce perfect code, but the entire title-author-date section was thrown into the body when it should have been part of the preamble.
- **authentic voice** - 4.7/10. This is subjective, but the “magic” part wasn’t really drawing me in.

Would I read this? Sure, if I was desperate. Would it be my go-to resource? Absolutely not.

This is a **6.8/10** from me.

## ChatGPT

All hail ChatGPT, our savior when it comes to homework problems! To keep it fair, we’ll use the same prompts.

After the first prompt, it was already pretty great. ChatGPT packed a lot of information into 3 pages. Definitely better than Copilot’s first attempt, I’d say - one warning vs. four errors.

After the second prompt, ChatGPT added two more pages. The style of the code blocks was much cleaner than that of Copilot’s. 

After the third prompt, there were more issues than before, but they were nothing compared to the monstrosity that Copilot made in its first attempt. The only downside is that there are now 12 errors. [Here's ChatGPT's tutorial.](https://www.overleaf.com/read/frxwgbhrpzcf#f6c810)

I think I’m being too lenient because we started with Copilot, but this is pretty nice except for some parts that made me cringe. 

- **structure** - 9.5/10. Super readable, but it doesn’t explicitly tell you what a preamble is and assumes knowledge.
- **accuracy & reproducibility** - 8.7/10. This code is ten times easier to copy/paste than the code in the Copilot-generated tutorial.
- **authentic voice** - 6.8/10, if we’re rating this by human standards. It’s obvious an AI wrote it, but it’s exactly the voice of ChatGPT.

I’d read this. Not as a first resource, but as a supplementary resource to something more detailed - [Learn LaTeX in 30 Minutes](https://www.overleaf.com/learn/latex/Learn_LaTeX_in_30_minutes), maybe. It would also be nice to have some rendered equations for reference.

Overall, **8.3/10**. Not extraordinary, but at least writers of documentation can breathe a sigh of relief knowing that AI isn’t taking over their jobs anytime soon.

(Also, I think you should be drinking coffee *before* writing LaTeX…but that’s just me.)

## Instagram’s Meta AI

*This* one was a struggle. I don’t know exactly what to say about it, so [see for yourself...](https://www.overleaf.com/read/dxncjqntjvrc#16f96c)

- **structure** - 6/10. It’s a little bit choppy without much explanation, and it doesn’t end with a solid conclusion like the other two. Some parts are super unclear, especially since it doesn’t have much written text and just throws code blocks at you.
- **accuracy & reproducibility** - 9.2/10. It’s technically accurate, but not very accessible. The code is really hard to follow without context.
- **authentic voice** - 1/10. Bland.

I’m not a huge fan, so this is a **5.4/10**.

## Final verdict

ChatGPT won this one. There’s no doubt about it. Copilot comes second, and Meta last.

I actually had the highest hopes for Copilot, but this was a pleasant surprise. ChatGPT on top!

## An added bonus

I couldn’t just stop there. I had to honor the younger generation’s language (although the oldest of them are just one year younger than me). Here’s a [brainrot version of what Copilot made.](https://www.overleaf.com/read/snmvxwyxvbcw#a3588e) 

Not bad! (64 errors, though…)

Have a blessed day, loves. Thanks for reading!
